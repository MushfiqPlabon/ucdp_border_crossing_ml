{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iiFy1lQzsi97"
   },
   "source": [
    "**Dataset used:** https://ucdp.uu.se/country/771\n",
    "\n",
    "**Goal of ML:** To predict the likelihood of cross-border conflict events involving Bangladesh using historical event-level data, in a theoretical early-warning scenario intended to inform preparedness and alertness planning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_lYpkCLI7Dlh"
   },
   "source": [
    "# Initial Setup (needed for Google Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bm3loisR7CBh",
    "outputId": "a2e00df7-6623-480a-affd-f0d38ab4a762"
   },
   "outputs": [],
   "source": [
    "# %pip install ydata-profiling gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R06jSYDc7Lyn",
    "outputId": "f0dcd8b7-8dd9-48d6-e3ff-51c7727a85c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from ydata_profiling import ProfileReport\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import gradio as gr\n",
    "\n",
    "print(\"Libraries loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfUBlYMq7ZKk"
   },
   "source": [
    "# Task 1: Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "8YqTWDM_7eYG",
    "outputId": "7fb94332-6560-4db9-d931-507919d5c15d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded. Shape: (693, 47)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>relid</th>\n",
       "      <th>year</th>\n",
       "      <th>active_year</th>\n",
       "      <th>code_status</th>\n",
       "      <th>type_of_violence</th>\n",
       "      <th>conflict_dset_id</th>\n",
       "      <th>conflict_new_id</th>\n",
       "      <th>conflict_name</th>\n",
       "      <th>dyad_dset_id</th>\n",
       "      <th>...</th>\n",
       "      <th>date_prec</th>\n",
       "      <th>date_start</th>\n",
       "      <th>date_end</th>\n",
       "      <th>deaths_a</th>\n",
       "      <th>deaths_b</th>\n",
       "      <th>deaths_civilians</th>\n",
       "      <th>deaths_unknown</th>\n",
       "      <th>best_est</th>\n",
       "      <th>high_est</th>\n",
       "      <th>low_est</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210432</td>\n",
       "      <td>BNG-2015-3-2087-0</td>\n",
       "      <td>2015</td>\n",
       "      <td>False</td>\n",
       "      <td>Clear</td>\n",
       "      <td>3</td>\n",
       "      <td>1218</td>\n",
       "      <td>2009</td>\n",
       "      <td>JMB - Civilians</td>\n",
       "      <td>1218</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>09/04/2015 00:00:00</td>\n",
       "      <td>09/04/2015 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>210433</td>\n",
       "      <td>BNG-2015-3-1076-1</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>Clear</td>\n",
       "      <td>3</td>\n",
       "      <td>234</td>\n",
       "      <td>506</td>\n",
       "      <td>IS - Civilians</td>\n",
       "      <td>234</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>09/28/2015 00:00:00</td>\n",
       "      <td>09/28/2015 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210436</td>\n",
       "      <td>BNG-2015-3-1076-2</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>Clear</td>\n",
       "      <td>3</td>\n",
       "      <td>234</td>\n",
       "      <td>506</td>\n",
       "      <td>IS - Civilians</td>\n",
       "      <td>234</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10/03/2015 00:00:00</td>\n",
       "      <td>10/03/2015 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>210459</td>\n",
       "      <td>BNG-2015-3-1076-3</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>Clear</td>\n",
       "      <td>3</td>\n",
       "      <td>234</td>\n",
       "      <td>506</td>\n",
       "      <td>IS - Civilians</td>\n",
       "      <td>234</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10/24/2015 00:00:00</td>\n",
       "      <td>10/24/2015 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>210470</td>\n",
       "      <td>BNG-2015-1-14718-0</td>\n",
       "      <td>2015</td>\n",
       "      <td>False</td>\n",
       "      <td>Clear</td>\n",
       "      <td>1</td>\n",
       "      <td>13674</td>\n",
       "      <td>13674</td>\n",
       "      <td>Bangladesh: Islamic State</td>\n",
       "      <td>14718</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>11/04/2015 00:00:00</td>\n",
       "      <td>11/04/2015 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id               relid  year  active_year code_status  \\\n",
       "0  210432   BNG-2015-3-2087-0  2015        False       Clear   \n",
       "1  210433   BNG-2015-3-1076-1  2015         True       Clear   \n",
       "2  210436   BNG-2015-3-1076-2  2015         True       Clear   \n",
       "3  210459   BNG-2015-3-1076-3  2015         True       Clear   \n",
       "4  210470  BNG-2015-1-14718-0  2015        False       Clear   \n",
       "\n",
       "   type_of_violence  conflict_dset_id  conflict_new_id  \\\n",
       "0                 3              1218             2009   \n",
       "1                 3               234              506   \n",
       "2                 3               234              506   \n",
       "3                 3               234              506   \n",
       "4                 1             13674            13674   \n",
       "\n",
       "               conflict_name  dyad_dset_id  ...  date_prec  \\\n",
       "0            JMB - Civilians          1218  ...          1   \n",
       "1             IS - Civilians           234  ...          1   \n",
       "2             IS - Civilians           234  ...          1   \n",
       "3             IS - Civilians           234  ...          1   \n",
       "4  Bangladesh: Islamic State         14718  ...          1   \n",
       "\n",
       "            date_start             date_end  deaths_a deaths_b  \\\n",
       "0  09/04/2015 00:00:00  09/04/2015 00:00:00         0        0   \n",
       "1  09/28/2015 00:00:00  09/28/2015 00:00:00         0        0   \n",
       "2  10/03/2015 00:00:00  10/03/2015 00:00:00         0        0   \n",
       "3  10/24/2015 00:00:00  10/24/2015 00:00:00         0        0   \n",
       "4  11/04/2015 00:00:00  11/04/2015 00:00:00         1        0   \n",
       "\n",
       "   deaths_civilians  deaths_unknown best_est  high_est low_est  \n",
       "0                 2               0        2         2       2  \n",
       "1                 1               0        1         1       1  \n",
       "2                 1               0        1         1       1  \n",
       "3                 1               0        1         1       1  \n",
       "4                 0               0        1         1       1  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"gedevents-2026-01-17.csv\", index_col=False)\n",
    "print(f\"Data loaded. Shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RRUkezgxfShX"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b8d1a7992c45539df80b10bbaeb616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 1780.72it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae145efd18642c4ad6464300a6d82a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30152934e5fc4b619696369bd3c6c3b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "207dc1faac34438597727027bd9185bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Subtask: EDA\n",
    "ProfileReport(df, title=\"EDA\", explorative=True).to_file(\n",
    "    \"EDA-Report.html\"\n",
    ")  # For generating downloadeable HTML\n",
    "# ProfileReport(df, title=\"EDA\", explorative=True) # To view inside colab without requiring download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxymYEZM7uGM"
   },
   "source": [
    "\n",
    "\n",
    "*   The dataset contains event-level armed conflict records from the Uppsala Conflict Data Program (UCDP).\n",
    "\n",
    "*   Each row represents a single conflict event with temporal, geographic, and conflict-related attributes.\n",
    "\n",
    "*   The objective is to predict whether an event involved a cross-border incident."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXk-CtmhApbW"
   },
   "source": [
    "# Task 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZoH1zxVsA9MF",
    "outputId": "03420865-e4a5-4d46-f83b-652558e87d84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Events: 693\n",
      "Identified Border Violations: 8\n",
      "Training Set Size: 554\n",
      "Testing Set Size: 139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56017/1450385517.py:49: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Target Definition (Feature Engineering)\n",
    "# Identifying Border Violations (Class 1) vs Internal (Class 0)\n",
    "def define_target(row: pd.Series) -> int:\n",
    "    text = f\"{str(row['side_a'])} {str(row['side_b'])} {str(row.get('source_headline', ''))}\".lower()\n",
    "    keywords = [\n",
    "        \"border\",\n",
    "        \"bsf\",\n",
    "        \"bgb\",\n",
    "        \"bgp\",\n",
    "        \"bdr\",\n",
    "        \"rifles\",\n",
    "        \"crossing\",\n",
    "        \"fence\",\n",
    "        \"pushback\",\n",
    "        \"no man's land\",\n",
    "        \"zero line\",\n",
    "    ]\n",
    "    return 1 if any(k in text for k in keywords) else 0\n",
    "\n",
    "\n",
    "df[\"is_border_violation\"] = df.apply(define_target, axis=1)\n",
    "\n",
    "# Step 2: Feature Extraction (Getting month)\n",
    "df[\"month\"] = pd.to_datetime(df[\"date_start\"]).dt.month\n",
    "\n",
    "# Step 3: Handling Missing Values\n",
    "df = df.dropna(subset=[\"latitude\", \"longitude\", \"year\", \"type_of_violence\", \"month\"])\n",
    "\n",
    "# Step 4: Feature Selection\n",
    "X = df[[\"latitude\", \"longitude\", \"year\", \"month\", \"type_of_violence\"]]\n",
    "y = df[\"is_border_violation\"]\n",
    "\n",
    "# Step 5: Stratified Split (80/20)\n",
    "# Uses stratify=y to maintain the 8/693 ratio in both sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Total Events: {len(df)}\")\n",
    "print(f\"Identified Border Violations: {df['is_border_violation'].sum()}\")\n",
    "print(f\"Training Set Size: {len(X_train)}\")\n",
    "print(f\"Testing Set Size: {len(X_test)}\")\n",
    "\n",
    "# Visualising the distribution of border violations in the training set\n",
    "sns.countplot(x=y_train)\n",
    "plt.title(\"Distribution of Border Violations in Training Set\")\n",
    "plt.xlabel(\"Is Border Violation\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCIff60aBFQW"
   },
   "source": [
    "# Task 3: Pipeline Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yVow1_R9BS51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Events: 693\n",
      "Identified Border Violations: 8\n",
      "Training Set Size: 554\n"
     ]
    }
   ],
   "source": [
    "# Scaling numerical coordinates/years and encoding categorical violence types\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"num\", StandardScaler(), [\"latitude\", \"longitude\", \"year\", \"month\"]),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), [\"type_of_violence\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "custom_weights = {\n",
    "    0: 1,\n",
    "    1: 100,\n",
    "}  # Forcing the model to value 1 border event as much as 100 internal ones\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"pre\", preprocessor),\n",
    "        (\n",
    "            \"clf\",\n",
    "            RandomForestClassifier(\n",
    "                n_estimators=500,  # More trees to reduce variance on the 8 samples\n",
    "                class_weight=custom_weights,\n",
    "                min_samples_leaf=1,  # REQUIRED: With only 8 samples, we can't require 2 per leaf\n",
    "                max_depth=None,  # Letting the tree grow deep enough to capture the specific border coords\n",
    "                random_state=42,\n",
    "                criterion=\"entropy\",  # Better for our heavily imbalanced dataset\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Visualising dataset sizes\n",
    "print(f\"Total Events: {len(df)}\")\n",
    "print(f\"Identified Border Violations: {df['is_border_violation'].sum()}\")\n",
    "print(f\"Training Set Size: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bj71S1ZABoHk"
   },
   "source": [
    "# Task 4: Primary Model Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhTRqSh6BuZO"
   },
   "source": [
    "**Selection:** Random Forest Classifier.\n",
    "\n",
    "**Justification:** The YData showed that conflict events are non-linearly distributed across coordinates. Random Forest is ideal for this dataset because it handles the non-linear relationship between geography and conflict types well.\n",
    "It is inherently robust to the noise present in UCDP event reporting and offers 'class_weight' parameters to handle the rarity of border events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRhFxrlXCNXb"
   },
   "source": [
    "# Task 5: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "liC47VcnCOmf",
    "outputId": "eae15b90-538c-4d36-cc5a-cdf270410b2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Model Training Complete.\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "print(\"Initial Model Training Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANcXKPDFFVq5"
   },
   "source": [
    "# Task 6: Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5NzoyMQZFYks"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Robust Cross-Validation (100 runs per model)...\n",
      "--- BATTLE RESULTS ---\n",
      "RandomForest (Balanced): F1=0.576 (+/- 0.150) | Border Recall=0.170\n",
      "AdaBoost (Stumps): F1=0.594 (+/- 0.133) | Border Recall=0.320\n",
      "OneClassSVM (Anomaly): F1=0.556 (+/- 0.056) | Border Recall=0.745\n",
      "Best Model Selected: OneClassSVM (Anomaly)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56017/1662298740.py:88: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Robust Validation Setup ---\n",
    "rskf = RepeatedStratifiedKFold(n_splits=4, n_repeats=25, random_state=42)\n",
    "\n",
    "\n",
    "# --- 2. Optimising Manual Upsampling Function ---\n",
    "def upsample_minority(\n",
    "    X: pd.DataFrame, y: pd.Series, target_count: int = 500\n",
    ") -> tuple[pd.DataFrame, pd.Series]:\n",
    "    # Working with indices to avoid expensive dataframe copying\n",
    "    minority_indices = y[y == 1].index.to_numpy()\n",
    "    majority_indices = y[y == 0].index.to_numpy()\n",
    "\n",
    "    # Randomly sampling minority indices with replacement\n",
    "    upsampled_min_idx = np.random.choice(\n",
    "        minority_indices, size=target_count, replace=True\n",
    "    )\n",
    "\n",
    "    # Combining majority and upsampled minority indices\n",
    "    new_indices = np.concatenate([majority_indices, upsampled_min_idx])\n",
    "    np.random.shuffle(new_indices)\n",
    "\n",
    "    return X.loc[new_indices], y.loc[new_indices]\n",
    "\n",
    "\n",
    "# --- 3. Model Configurations ---\n",
    "models = {\n",
    "    \"RandomForest (Balanced)\": RandomForestClassifier(\n",
    "        n_estimators=1000,\n",
    "        max_depth=5,\n",
    "        class_weight=\"balanced_subsample\",\n",
    "        random_state=42,\n",
    "    ),\n",
    "    \"AdaBoost (Stumps)\": AdaBoostClassifier(\n",
    "        estimator=DecisionTreeClassifier(max_depth=1), n_estimators=50, random_state=42\n",
    "    ),\n",
    "    \"OneClassSVM (Anomaly)\": OneClassSVM(kernel=\"rbf\", nu=0.01),\n",
    "}\n",
    "\n",
    "# --- 4. The Comparison Loop ---\n",
    "results = {name: {\"f1\": [], \"recall\": []} for name in models}\n",
    "print(\"Starting Robust Cross-Validation (100 runs per model)...\")\n",
    "\n",
    "for i, (train_idx, val_idx) in enumerate(rskf.split(X_train, y_train)):\n",
    "    # Slicing using indices (View vs Copy optimization)\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "    # Pipeline Processing\n",
    "    X_tr_proc = preprocessor.fit_transform(X_tr)\n",
    "    X_val_proc = preprocessor.transform(X_val)\n",
    "\n",
    "    # Applying Upsampling only to Training Data (To Prevent Leakage)\n",
    "    X_tr_up, y_tr_up = upsample_minority(\n",
    "        pd.DataFrame(X_tr_proc, index=X_tr.index), y_tr, target_count=len(y_tr)\n",
    "    )\n",
    "\n",
    "    for name, model in models.items():\n",
    "        if \"OneClass\" in name:\n",
    "            # Anomaly detection trains only on Majority Class (Internal Conflict)\n",
    "            model.fit(X_tr_proc[y_tr == 0])\n",
    "            preds = np.where(model.predict(X_val_proc) == -1, 1, 0)\n",
    "        else:\n",
    "            # Classifiers train on Upsampled Balanced Data\n",
    "            model.fit(X_tr_up, y_tr_up)\n",
    "            preds = model.predict(X_val_proc)\n",
    "\n",
    "        results[name][\"f1\"].append(f1_score(y_val, preds, average=\"macro\"))\n",
    "        results[name][\"recall\"].append(recall_score(y_val, preds, pos_label=1))\n",
    "\n",
    "# --- 5. Displaying Results ---\n",
    "print(\"--- BATTLE RESULTS ---\")\n",
    "for name, metrics in results.items():\n",
    "    print(\n",
    "        f\"{name}: F1={np.mean(metrics['f1']):.3f} (+/- {np.std(metrics['f1']):.3f}) | Border Recall={np.mean(metrics['recall']):.3f}\"\n",
    "    )\n",
    "\n",
    "# --- 6. Visualize Results ---\n",
    "best_model_name = max(results, key=lambda n: np.mean(results[n][\"recall\"]))\n",
    "best_model = models[best_model_name]\n",
    "print(f\"Best Model Selected: {best_model_name}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "model_names = list(results.keys())\n",
    "f1_means = [np.mean(results[name][\"f1\"]) for name in model_names]\n",
    "plt.bar(model_names, f1_means, color=[\"skyblue\", \"salmon\", \"lightgreen\"])\n",
    "plt.ylabel(\"Mean F1 Score\")\n",
    "plt.title(\"Model Comparison: Mean F1 Scores\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 7: Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning AdaBoost (Stumps)...\n",
      "Parameters to test: {'n_estimators': [50, 100, 200], 'learning_rate': [0.5, 1.0, 1.5]}\n",
      "Best Parameters Found: {'learning_rate': 1.0, 'n_estimators': 50}\n",
      "Best Grid Score: 0.9936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56017/84521351.py:36: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Optimising the best performing model (likely AdaBoost) from the Cross-Validation step.\n",
    "# Parameters tested: n_estimators, learning_rate\n",
    "\n",
    "prob_model_name = \"AdaBoost (Stumps)\"\n",
    "base_model = models[prob_model_name]\n",
    "\n",
    "param_grid = {\"n_estimators\": [50, 100, 200], \"learning_rate\": [0.5, 1.0, 1.5]}\n",
    "\n",
    "print(f\"Tuning {prob_model_name}...\")\n",
    "print(f\"Parameters to test: {param_grid}\")\n",
    "\n",
    "# Using a simplified CV for tuning speed, utilizing the preprocessor\n",
    "grid = GridSearchCV(base_model, param_grid, cv=3, scoring=\"f1_macro\", n_jobs=-1)\n",
    "\n",
    "# Preprocessing full training set for grid search\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "# Upsampling once for grid search to handle imbalance during tuning\n",
    "X_train_up, y_train_up = upsample_minority(\n",
    "    pd.DataFrame(X_train_proc, index=X_train.index), y_train, target_count=len(y_train)\n",
    ")\n",
    "\n",
    "grid.fit(X_train_up, y_train_up)\n",
    "\n",
    "print(f\"Best Parameters Found: {grid.best_params_}\")\n",
    "print(f\"Best Grid Score: {grid.best_score_:.4f}\")\n",
    "\n",
    "# Visualising parameter effects\n",
    "results_df = pd.DataFrame(grid.cv_results_)\n",
    "pivot_table = results_df.pivot_table(\n",
    "    values=\"mean_test_score\", index=\"param_n_estimators\", columns=\"param_learning_rate\"\n",
    ")\n",
    "sns.heatmap(pivot_table, annot=True, fmt=\".4f\", cmap=\"YlGnBu\")\n",
    "plt.title(\"Grid Search Mean Test Scores\")\n",
    "plt.xlabel(\"Learning Rate\")\n",
    "plt.ylabel(\"Number of Estimators\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 8: Best Model Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Selected Probability Model: AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1),\n",
      "                   random_state=42)\n",
      "Final Selected Anomaly Model: OneClassSVM(nu=0.01)\n",
      "Best Models Selected and Unified into Hybrid System.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9343    0.9660       137\n",
      "           1     0.1818    1.0000    0.3077         2\n",
      "\n",
      "    accuracy                         0.9353       139\n",
      "   macro avg     0.5909    0.9672    0.6369       139\n",
      "weighted avg     0.9882    0.9353    0.9566       139\n",
      "\n",
      "Hybrid System Evaluation Complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56017/2800845256.py:36: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Selecting the final best-performing model (likely Adaboost) based on tuning results\n",
    "best_prob_model = grid.best_estimator_\n",
    "print(f\"Final Selected Probability Model: {best_prob_model}\")\n",
    "\n",
    "# Refitting the complementary Anomaly Model (OneClassSVM detects outliers) for a Hybrid System\n",
    "anomaly_model_name = \"OneClassSVM (Anomaly)\"\n",
    "anomaly_model = models[anomaly_model_name]\n",
    "anomaly_model.fit(X_train_proc[y_train == 0])\n",
    "print(f\"Final Selected Anomaly Model: {anomaly_model}\")\n",
    "\n",
    "\n",
    "# Wrapping into a Hybrid System for Deployment\n",
    "class HybridTacticalModel:\n",
    "    def __init__(self, preprocessor, prob_model, anomaly_model):\n",
    "        self.preprocessor = preprocessor\n",
    "        self.prob_model = prob_model\n",
    "        self.anomaly_model = anomaly_model\n",
    "\n",
    "    def analyze(self, X_raw):\n",
    "        X_proc = self.preprocessor.transform(X_raw)\n",
    "        risk_prob = self.prob_model.predict_proba(X_proc)[0][1]\n",
    "        is_anomaly = self.anomaly_model.predict(X_proc)[0] == -1\n",
    "        return {\"probability\": float(risk_prob), \"anomaly_detected\": bool(is_anomaly)}\n",
    "\n",
    "\n",
    "hybrid_system = HybridTacticalModel(preprocessor, best_prob_model, anomaly_model)\n",
    "print(\"Best Models Selected and Unified into Hybrid System.\")\n",
    "\n",
    "# Visualising the Hybrid System's Predictions on Test Set\n",
    "X_test_proc = preprocessor.transform(X_test)\n",
    "prob_preds = best_prob_model.predict(X_test_proc)\n",
    "anomaly_preds = anomaly_model.predict(X_test_proc)\n",
    "hybrid_preds = np.where((prob_preds > 0.5) | (anomaly_preds == -1), 1, 0)\n",
    "print(classification_report(y_test, hybrid_preds, digits=4))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, hybrid_preds)\n",
    "plt.show()\n",
    "print(\"Hybrid System Evaluation Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 9: Model Performance Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FINAL TEST SET PERFORMANCE ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       137\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.99       139\n",
      "   macro avg       1.00      0.75      0.83       139\n",
      "weighted avg       0.99      0.99      0.99       139\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56017/213411378.py:12: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "/tmp/ipykernel_56017/213411378.py:37: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the test set and printing comprehensive metrics suitable for the problem type.\n",
    "print(\"--- FINAL TEST SET PERFORMANCE ---\")\n",
    "\n",
    "# We evaluate the probability component (Precision/Recall)\n",
    "X_test_proc = preprocessor.transform(X_test)\n",
    "y_pred_prob = best_prob_model.predict(X_test_proc)\n",
    "\n",
    "# Probability Model Evaluation\n",
    "print(classification_report(y_test, y_pred_prob))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_prob, cmap=\"Greens\")\n",
    "plt.title(\"Final Model Performance (Test Set)\")\n",
    "plt.show()\n",
    "\n",
    "# Visualising prediction vs actuals\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(\n",
    "    X_test[\"longitude\"],\n",
    "    X_test[\"latitude\"],\n",
    "    c=y_test,\n",
    "    cmap=\"coolwarm\",\n",
    "    alpha=0.7,\n",
    "    label=\"Actual\",\n",
    ")\n",
    "plt.scatter(\n",
    "    X_test[\"longitude\"],\n",
    "    X_test[\"latitude\"],\n",
    "    c=y_pred_prob,\n",
    "    cmap=\"coolwarm\",\n",
    "    alpha=0.4,\n",
    "    marker=\"x\",\n",
    "    label=\"Predicted\",\n",
    ")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.title(\"Actual vs Predicted Border Violations on Test Set\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xcHY9rzKkMzL"
   },
   "source": [
    "# Task 10: Pickling the Model to prepare for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unified Hybrid System saved to 'model.pkl'. Ready for deployment.\n"
     ]
    }
   ],
   "source": [
    "with open(\"model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(hybrid_system, f)\n",
    "print(\"Unified Hybrid System saved to 'model.pkl'. Ready for deployment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradio Interface for Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECTORS = {\n",
    "#     \"Teknaf Border\": (20.86, 92.30),\n",
    "#     \"Ukhiya Zone\": (21.16, 92.14),\n",
    "#     \"Bandarban Hills\": (22.19, 92.21),\n",
    "#     \"Sylhet Border\": (24.89, 91.86),\n",
    "#     \"Dhaka Central\": (23.81, 90.41),\n",
    "#     \"Chittagong Port\": (22.34, 91.83),\n",
    "#     \"Cox's Bazar Coast\": (21.42, 91.98),\n",
    "#     \"Rangamati Hills\": (22.65, 92.19),\n",
    "#     \"Khulna Sundarbans\": (22.45, 89.54),\n",
    "#     \"Rajshahi Border\": (24.37, 88.60),\n",
    "#     \"Comilla Border\": (23.47, 91.18),\n",
    "#     \"Dinajpur Border\": (25.63, 88.67),\n",
    "# }\n",
    "\n",
    "# MONTHS = {\n",
    "#     \"Jan\": 1,\n",
    "#     \"Feb\": 2,\n",
    "#     \"Mar\": 3,\n",
    "#     \"Apr\": 4,\n",
    "#     \"May\": 5,\n",
    "#     \"Jun\": 6,\n",
    "#     \"Jul\": 7,\n",
    "#     \"Aug\": 8,\n",
    "#     \"Sep\": 9,\n",
    "#     \"Oct\": 10,\n",
    "#     \"Nov\": 11,\n",
    "#     \"Dec\": 12,\n",
    "# }\n",
    "\n",
    "# V_TYPES = {\"State-based Action\": 1, \"Non-state Activity\": 2, \"Civilian Attacks\": 3}\n",
    "\n",
    "\n",
    "# # --- 4. Prediction Function ---\n",
    "# def hybrid_predict(year, sector, month, violence):\n",
    "#     try:\n",
    "#         # A. Map Inputs\n",
    "#         lat, lon = SECTORS[sector]\n",
    "#         m_num = MONTHS[month]\n",
    "#         vt = V_TYPES[violence]\n",
    "\n",
    "#         # B. Create input DataFrame\n",
    "#         input_data = pd.DataFrame(\n",
    "#             [[float(lat), float(lon), int(year), int(m_num), int(vt)]],\n",
    "#             columns=[\"latitude\", \"longitude\", \"year\", \"month\", \"type_of_violence\"],\n",
    "#         )\n",
    "\n",
    "#         # C. Get Hybrid Intelligence\n",
    "#         analysis = hybrid_system.analyze(input_data)\n",
    "#         risk_prob = analysis[\"probability\"]\n",
    "#         anomaly = analysis[\"anomaly_detected\"]\n",
    "\n",
    "#         # D. Unified Status Logic\n",
    "#         if risk_prob >= 0.20:\n",
    "#             status = \"ðŸ”´ RED ALERT: High Probability Border Threat\"\n",
    "#         elif anomaly:\n",
    "#             status = \"ðŸŸ¡ YELLOW ALERT: Unusual Activity (Anomaly Detected)\"\n",
    "#         else:\n",
    "#             status = \"ðŸŸ¢ GREEN: Routine Internal Patterns\"\n",
    "\n",
    "#         return {\n",
    "#             \"Tactical_Status\": status,\n",
    "#             \"Intelligence_Signals\": {\n",
    "#                 \"Historical_Pattern_Match_Prob\": f\"{risk_prob:.2%}\",\n",
    "#                 \"Outlier_Detection_Warning\": \"ACTIVE\" if anomaly else \"None\",\n",
    "#             },\n",
    "#             \"Commander_Note\": \"Yellow alerts indicate events that don't match standard internal conflict patterns and should be verified by ground sensors/scouts.\",\n",
    "#             \"Input_Context\": {\n",
    "#                 \"Year\": int(year),\n",
    "#                 \"Sector\": sector,\n",
    "#                 \"Month\": month,\n",
    "#                 \"Conflict_Type\": violence,\n",
    "#             },\n",
    "#         }\n",
    "\n",
    "#     except Exception as e:\n",
    "#         return {\"Error\": str(e)}\n",
    "\n",
    "\n",
    "# # --- 5. Interface Construction ---\n",
    "# ui = gr.Interface(\n",
    "#     fn=hybrid_predict,\n",
    "#     inputs=[\n",
    "#         gr.Number(value=2026, label=\"Forecast Year\"),\n",
    "#         gr.Dropdown(\n",
    "#             choices=list(SECTORS.keys()),\n",
    "#             label=\"Sector Selection\",\n",
    "#             value=\"Teknaf Border\",\n",
    "#         ),\n",
    "#         gr.Dropdown(choices=list(MONTHS.keys()), label=\"Forecast Month\", value=\"Jan\"),\n",
    "#         gr.Dropdown(\n",
    "#             choices=list(V_TYPES.keys()),\n",
    "#             label=\"Conflict Category\",\n",
    "#             value=\"State-based Action\",\n",
    "#         ),\n",
    "#     ],\n",
    "#     outputs=gr.JSON(label=\"Tactical Intelligence Report\"),\n",
    "#     title=\"Hybrid Early Warning System (HEWS)\",\n",
    "#     description=\"A theoretical dual-signal intelligence system combining Historical Probability (AdaBoost) and Anomaly Detection (SVM). Designed for cross-border conflict prediction. Select parameters and receive a tactical status report. Yellow alerts indicate events that don't match standard internal conflict patterns and should be verified by ground sensors/scouts. The dataset used is from UCDP Border Crossing dataset exported on 17th Januay 2026, it only includes conflict data up to year 2024.\",\n",
    "# )\n",
    "\n",
    "# # --- 6. Launch ---\n",
    "# if __name__ == \"__main__\":\n",
    "#     ui.launch(\n",
    "#         share=True,\n",
    "#         debug=True,\n",
    "#         pwa=True\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ucdp-border-crossing-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
